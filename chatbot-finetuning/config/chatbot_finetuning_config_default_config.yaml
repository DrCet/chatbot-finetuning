model:
  name: "meta-llama/Llama-3-8b"
  tokenizer: "meta-llama/Llama-3-8b"
dataset:
  path: null
  format: "json"
training:
  epochs: 3
  batch_size: 4
  learning_rate: 2e-5
output:
  dir: "./finetuned_model"
  push_to_hub: false