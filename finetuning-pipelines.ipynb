{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"cd ..","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T22:38:58.132208Z","iopub.execute_input":"2025-05-11T22:38:58.132870Z","iopub.status.idle":"2025-05-11T22:38:58.138243Z","shell.execute_reply.started":"2025-05-11T22:38:58.132839Z","shell.execute_reply":"2025-05-11T22:38:58.137406Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!rm -r finetune-with-huggingface","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T22:38:59.023530Z","iopub.execute_input":"2025-05-11T22:38:59.023937Z","iopub.status.idle":"2025-05-11T22:38:59.999518Z","shell.execute_reply.started":"2025-05-11T22:38:59.023901Z","shell.execute_reply":"2025-05-11T22:38:59.998334Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"!git clone https://github.com/DrCet/finetune-with-huggingface","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T22:39:04.636041Z","iopub.execute_input":"2025-05-11T22:39:04.636394Z","iopub.status.idle":"2025-05-11T22:39:05.110508Z","shell.execute_reply.started":"2025-05-11T22:39:04.636364Z","shell.execute_reply":"2025-05-11T22:39:05.109660Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'finetune-with-huggingface'...\nremote: Enumerating objects: 586, done.\u001b[K\nremote: Counting objects: 100% (62/62), done.\u001b[K\nremote: Compressing objects: 100% (43/43), done.\u001b[K\nremote: Total 586 (delta 35), reused 42 (delta 17), pack-reused 524 (from 1)\u001b[K\nReceiving objects: 100% (586/586), 111.48 KiB | 3.72 MiB/s, done.\nResolving deltas: 100% (365/365), done.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"cd finetune-with-huggingface","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T22:39:06.487130Z","iopub.execute_input":"2025-05-11T22:39:06.487455Z","iopub.status.idle":"2025-05-11T22:39:06.493852Z","shell.execute_reply.started":"2025-05-11T22:39:06.487428Z","shell.execute_reply":"2025-05-11T22:39:06.492771Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/finetune-with-huggingface\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Finetune a image classifcation model","metadata":{}},{"cell_type":"code","source":"!python run_imageclass_finetuning.py ./finetune_json/imageclass.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T14:11:07.251951Z","iopub.execute_input":"2025-05-11T14:11:07.252621Z","iopub.status.idle":"2025-05-11T14:11:23.945880Z","shell.execute_reply.started":"2025-05-11T14:11:07.252593Z","shell.execute_reply":"2025-05-11T14:11:23.944961Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"2025-05-11 14:11:13.256525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746972673.281168    5546 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746972673.288491    5546 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nGenerating train split: 100%|██████| 9469/9469 [00:03<00:00, 3094.14 examples/s]\nGenerating validation split: 100%|█| 3925/3925 [00:00<00:00, 4172.22 examples/s]\n^C\nTraceback (most recent call last):\n  File \"/kaggle/working/chatbot-finetuning/run_imageclass_finetuning.py\", line 373, in <module>\n    main()\n  File \"/kaggle/working/chatbot-finetuning/run_imageclass_finetuning.py\", line 199, in main\n    raw_datasets['validation'] = load_dataset(\n                                 ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 2062, in load_dataset\n    builder_instance = load_dataset_builder(\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1782, in load_dataset_builder\n    dataset_module = dataset_module_factory(\n                     ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1601, in dataset_module_factory\n    ).get_module()\n      ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1134, in get_module\n    .dataset_info(\n     ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\", line 2664, in dataset_info\n    r = get_session().get(path, headers=headers, timeout=timeout, params=params)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 602, in get\n    return self.request(\"GET\", url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 96, in send\n    return super().send(request, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 534, in _make_request\n    response = conn.getresponse()\n               ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 516, in getresponse\n    httplib_response = super().getresponse()\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/http/client.py\", line 1395, in getresponse\n    response.begin()\n  File \"/usr/lib/python3.11/http/client.py\", line 325, in begin\n    version, status, reason = self._read_status()\n                              ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/http/client.py\", line 286, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/ssl.py\", line 1314, in recv_into\n    return self.read(nbytes, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/ssl.py\", line 1166, in read\n    return self._sslobj.read(len, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# Finetune a token classification model","metadata":{}},{"cell_type":"code","source":"!python run_tokenclass_finetuning.py ./finetune_json/tokenclass.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T13:54:00.919334Z","iopub.execute_input":"2025-05-11T13:54:00.919633Z","iopub.status.idle":"2025-05-11T13:55:32.491471Z","shell.execute_reply.started":"2025-05-11T13:54:00.919614Z","shell.execute_reply":"2025-05-11T13:55:32.490452Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"2025-05-11 13:54:06.092145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746971646.117417    4485 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746971646.127630    4485 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nREADME.md: 100%|███████████████████████████████| 347/347 [00:00<00:00, 2.93MB/s]\ntrain-00000-of-00001.parquet: 100%|████████| 49.3k/49.3k [00:00<00:00, 4.79MB/s]\nGenerating train split: 100%|███████| 100/100 [00:00<00:00, 16441.80 examples/s]\nconfig.json: 100%|█████████████████████████| 5.14k/5.14k [00:00<00:00, 27.4MB/s]\n[INFO|configuration_utils.py:693] 2025-05-11 13:54:12,388 >> loading configuration file config.json from cache at ./Medical-NER-cache/models--blaze999--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/config.json\n[INFO|configuration_utils.py:765] 2025-05-11 13:54:12,392 >> Model config DebertaV2Config {\n  \"architectures\": [\n    \"DebertaV2ForTokenClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"B-ANATOMICAL_STRUCTURE\",\n    \"1\": \"B-BODY_PART_ORGAN_OR_ORGAN_COMPONENT\",\n    \"2\": \"B-BODY_SUBSTANCE\",\n    \"3\": \"B-CARDINAL\",\n    \"4\": \"B-CELL\",\n    \"5\": \"B-CELL_COMPONENT\",\n    \"6\": \"B-CELL_FUNCTION\",\n    \"7\": \"B-CELL_OR_MOLECULAR_DYSFUNCTION\",\n    \"8\": \"B-CHEMICAL\",\n    \"9\": \"B-CORONAVIRUS\",\n    \"10\": \"B-DAILY_OR_RECREATIONAL_ACTIVITY\",\n    \"11\": \"B-DATE\",\n    \"12\": \"B-DIAGNOSTIC_PROCEDURE\",\n    \"13\": \"B-DISEASE_OR_SYNDROME\",\n    \"14\": \"B-EDUCATIONAL_ACTIVITY\",\n    \"15\": \"B-EUKARYOTE\",\n    \"16\": \"B-EVOLUTION\",\n    \"17\": \"B-EXPERIMENTAL_MODEL_OF_DISEASE\",\n    \"18\": \"B-FAC\",\n    \"19\": \"B-FOOD\",\n    \"20\": \"B-GENE_OR_GENOME\",\n    \"21\": \"B-GOVERNMENTAL_OR_REGULATORY_ACTIVITY\",\n    \"22\": \"B-GPE\",\n    \"23\": \"B-GROUP\",\n    \"24\": \"B-INDIVIDUAL_BEHAVIOR\",\n    \"25\": \"B-INJURY_OR_POISONING\",\n    \"26\": \"B-LABORATORY_OR_TEST_RESULT\",\n    \"27\": \"B-LABORATORY_PROCEDURE\",\n    \"28\": \"B-LIVESTOCK\",\n    \"29\": \"B-LOC\",\n    \"30\": \"B-MOLECULAR_FUNCTION\",\n    \"31\": \"B-MONEY\",\n    \"32\": \"B-NORP\",\n    \"33\": \"B-ORDINAL\",\n    \"34\": \"B-ORG\",\n    \"35\": \"B-ORGANISM\",\n    \"36\": \"B-ORGAN_OR_TISSUE_FUNCTION\",\n    \"37\": \"B-PERCENT\",\n    \"38\": \"B-PERSON\",\n    \"39\": \"B-PHYSICAL_SCIENCE\",\n    \"40\": \"B-PRODUCT\",\n    \"41\": \"B-QUANTITY\",\n    \"42\": \"B-RESEARCH_ACTIVITY\",\n    \"43\": \"B-SIGN_OR_SYMPTOM\",\n    \"44\": \"B-SOCIAL_BEHAVIOR\",\n    \"45\": \"B-SUBSTRATE\",\n    \"46\": \"B-THERAPEUTIC_OR_PREVENTIVE_PROCEDURE\",\n    \"47\": \"B-TIME\",\n    \"48\": \"B-TISSUE\",\n    \"49\": \"B-VIRAL_PROTEIN\",\n    \"50\": \"B-VIRUS\",\n    \"51\": \"B-WILDLIFE\",\n    \"52\": \"I-CARDINAL\",\n    \"53\": \"I-CELL\",\n    \"54\": \"I-CELL_COMPONENT\",\n    \"55\": \"I-CHEMICAL\",\n    \"56\": \"I-CORONAVIRUS\",\n    \"57\": \"I-DATE\",\n    \"58\": \"I-DIAGNOSTIC_PROCEDURE\",\n    \"59\": \"I-DISEASE_OR_SYNDROME\",\n    \"60\": \"I-EDUCATIONAL_ACTIVITY\",\n    \"61\": \"I-EVOLUTION\",\n    \"62\": \"I-EXPERIMENTAL_MODEL_OF_DISEASE\",\n    \"63\": \"I-FAC\",\n    \"64\": \"I-GENE_OR_GENOME\",\n    \"65\": \"I-GPE\",\n    \"66\": \"I-GROUP\",\n    \"67\": \"I-INJURY_OR_POISONING\",\n    \"68\": \"I-LABORATORY_PROCEDURE\",\n    \"69\": \"I-MONEY\",\n    \"70\": \"I-NORP\",\n    \"71\": \"I-ORG\",\n    \"72\": \"I-ORGANISM\",\n    \"73\": \"I-ORGAN_OR_TISSUE_FUNCTION\",\n    \"74\": \"I-PERCENT\",\n    \"75\": \"I-PERSON\",\n    \"76\": \"I-PHYSICAL_SCIENCE\",\n    \"77\": \"I-PRODUCT\",\n    \"78\": \"I-QUANTITY\",\n    \"79\": \"I-RESEARCH_ACTIVITY\",\n    \"80\": \"I-SIGN_OR_SYMPTOM\",\n    \"81\": \"I-THERAPEUTIC_OR_PREVENTIVE_PROCEDURE\",\n    \"82\": \"I-TIME\",\n    \"83\": \"I-TISSUE\",\n    \"84\": \"I-WILDLIFE\",\n    \"85\": \"Other\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"B-ANATOMICAL_STRUCTURE\": 0,\n    \"B-BODY_PART_ORGAN_OR_ORGAN_COMPONENT\": 1,\n    \"B-BODY_SUBSTANCE\": 2,\n    \"B-CARDINAL\": 3,\n    \"B-CELL\": 4,\n    \"B-CELL_COMPONENT\": 5,\n    \"B-CELL_FUNCTION\": 6,\n    \"B-CELL_OR_MOLECULAR_DYSFUNCTION\": 7,\n    \"B-CHEMICAL\": 8,\n    \"B-CORONAVIRUS\": 9,\n    \"B-DAILY_OR_RECREATIONAL_ACTIVITY\": 10,\n    \"B-DATE\": 11,\n    \"B-DIAGNOSTIC_PROCEDURE\": 12,\n    \"B-DISEASE_OR_SYNDROME\": 13,\n    \"B-EDUCATIONAL_ACTIVITY\": 14,\n    \"B-EUKARYOTE\": 15,\n    \"B-EVOLUTION\": 16,\n    \"B-EXPERIMENTAL_MODEL_OF_DISEASE\": 17,\n    \"B-FAC\": 18,\n    \"B-FOOD\": 19,\n    \"B-GENE_OR_GENOME\": 20,\n    \"B-GOVERNMENTAL_OR_REGULATORY_ACTIVITY\": 21,\n    \"B-GPE\": 22,\n    \"B-GROUP\": 23,\n    \"B-INDIVIDUAL_BEHAVIOR\": 24,\n    \"B-INJURY_OR_POISONING\": 25,\n    \"B-LABORATORY_OR_TEST_RESULT\": 26,\n    \"B-LABORATORY_PROCEDURE\": 27,\n    \"B-LIVESTOCK\": 28,\n    \"B-LOC\": 29,\n    \"B-MOLECULAR_FUNCTION\": 30,\n    \"B-MONEY\": 31,\n    \"B-NORP\": 32,\n    \"B-ORDINAL\": 33,\n    \"B-ORG\": 34,\n    \"B-ORGANISM\": 35,\n    \"B-ORGAN_OR_TISSUE_FUNCTION\": 36,\n    \"B-PERCENT\": 37,\n    \"B-PERSON\": 38,\n    \"B-PHYSICAL_SCIENCE\": 39,\n    \"B-PRODUCT\": 40,\n    \"B-QUANTITY\": 41,\n    \"B-RESEARCH_ACTIVITY\": 42,\n    \"B-SIGN_OR_SYMPTOM\": 43,\n    \"B-SOCIAL_BEHAVIOR\": 44,\n    \"B-SUBSTRATE\": 45,\n    \"B-THERAPEUTIC_OR_PREVENTIVE_PROCEDURE\": 46,\n    \"B-TIME\": 47,\n    \"B-TISSUE\": 48,\n    \"B-VIRAL_PROTEIN\": 49,\n    \"B-VIRUS\": 50,\n    \"B-WILDLIFE\": 51,\n    \"I-CARDINAL\": 52,\n    \"I-CELL\": 53,\n    \"I-CELL_COMPONENT\": 54,\n    \"I-CHEMICAL\": 55,\n    \"I-CORONAVIRUS\": 56,\n    \"I-DATE\": 57,\n    \"I-DIAGNOSTIC_PROCEDURE\": 58,\n    \"I-DISEASE_OR_SYNDROME\": 59,\n    \"I-EDUCATIONAL_ACTIVITY\": 60,\n    \"I-EVOLUTION\": 61,\n    \"I-EXPERIMENTAL_MODEL_OF_DISEASE\": 62,\n    \"I-FAC\": 63,\n    \"I-GENE_OR_GENOME\": 64,\n    \"I-GPE\": 65,\n    \"I-GROUP\": 66,\n    \"I-INJURY_OR_POISONING\": 67,\n    \"I-LABORATORY_PROCEDURE\": 68,\n    \"I-MONEY\": 69,\n    \"I-NORP\": 70,\n    \"I-ORG\": 71,\n    \"I-ORGANISM\": 72,\n    \"I-ORGAN_OR_TISSUE_FUNCTION\": 73,\n    \"I-PERCENT\": 74,\n    \"I-PERSON\": 75,\n    \"I-PHYSICAL_SCIENCE\": 76,\n    \"I-PRODUCT\": 77,\n    \"I-QUANTITY\": 78,\n    \"I-RESEARCH_ACTIVITY\": 79,\n    \"I-SIGN_OR_SYMPTOM\": 80,\n    \"I-THERAPEUTIC_OR_PREVENTIVE_PROCEDURE\": 81,\n    \"I-TIME\": 82,\n    \"I-TISSUE\": 83,\n    \"I-WILDLIFE\": 84,\n    \"Other\": 85\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"legacy\": true,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\ntokenizer_config.json: 100%|███████████████| 1.28k/1.28k [00:00<00:00, 7.59MB/s]\nspm.model: 100%|███████████████████████████| 2.46M/2.46M [00:00<00:00, 39.5MB/s]\ntokenizer.json: 100%|██████████████████████| 8.66M/8.66M [00:00<00:00, 38.9MB/s]\nadded_tokens.json: 100%|██████████████████████| 23.0/23.0 [00:00<00:00, 196kB/s]\nspecial_tokens_map.json: 100%|█████████████████| 286/286 [00:00<00:00, 3.08MB/s]\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:54:13,417 >> loading file spm.model from cache at ./Medical-NER-cache/models--blaze999--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/spm.model\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:54:13,417 >> loading file tokenizer.json from cache at ./Medical-NER-cache/models--blaze999--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/tokenizer.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:54:13,417 >> loading file added_tokens.json from cache at ./Medical-NER-cache/models--blaze999--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/added_tokens.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:54:13,417 >> loading file special_tokens_map.json from cache at ./Medical-NER-cache/models--blaze999--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/special_tokens_map.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:54:13,417 >> loading file tokenizer_config.json from cache at ./Medical-NER-cache/models--blaze999--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:54:13,417 >> loading file chat_template.jinja from cache at None\nPreprocess train dataset (num_proc=4): 100%|█| 85/85 [00:00<00:00, 87.45 example\nPreprocess train dataset (num_proc=4): 100%|█| 15/15 [00:00<00:00, 17.91 example\nmodel.safetensors: 100%|██████████████████████| 736M/736M [00:04<00:00, 152MB/s]\n[INFO|modeling_utils.py:1124] 2025-05-11 13:54:21,295 >> loading weights file model.safetensors from cache at ./Medical-NER-cache/models--blaze999--Medical-NER/snapshots/a9d5061193e969de80b24225f926cb224caac1ce/model.safetensors\n[INFO|modeling_utils.py:4930] 2025-05-11 13:54:21,430 >> All model checkpoint weights were used when initializing DebertaV2ForTokenClassification.\n\n[WARNING|modeling_utils.py:4951] 2025-05-11 13:54:21,430 >> Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at blaze999/Medical-NER and are newly initialized because the shapes did not match:\n- classifier.bias: found shape torch.Size([83]) in the checkpoint and torch.Size([86]) in the model instantiated\n- classifier.weight: found shape torch.Size([83, 768]) in the checkpoint and torch.Size([86, 768]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 13:54:21,432 >> tokenizer config file saved in trainer_output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 13:54:21,433 >> Special tokens file saved in trainer_output/special_tokens_map.json\n[INFO|configuration_utils.py:419] 2025-05-11 13:54:21,467 >> Configuration saved in trainer_output/config.json\n[INFO|trainer.py:698] 2025-05-11 13:54:22,002 >> max_steps is given, it will override any value given in num_train_epochs\n[INFO|trainer.py:2414] 2025-05-11 13:54:22,450 >> ***** Running training *****\n[INFO|trainer.py:2415] 2025-05-11 13:54:22,450 >>   Num examples = 85\n[INFO|trainer.py:2416] 2025-05-11 13:54:22,450 >>   Num Epochs = 10\n[INFO|trainer.py:2417] 2025-05-11 13:54:22,450 >>   Instantaneous batch size per device = 2\n[INFO|trainer.py:2419] 2025-05-11 13:54:22,450 >>   Training with DataParallel so batch size has been adjusted to: 4\n[INFO|trainer.py:2420] 2025-05-11 13:54:22,450 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n[INFO|trainer.py:2421] 2025-05-11 13:54:22,450 >>   Gradient Accumulation steps = 2\n[INFO|trainer.py:2422] 2025-05-11 13:54:22,450 >>   Total optimization steps = 100\n[INFO|trainer.py:2423] 2025-05-11 13:54:22,451 >>   Number of trainable parameters = 183,897,686\n  0%|                                                   | 0/100 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-05-11 13:54:22,461 >> You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 3.3052, 'grad_norm': 2.9358479976654053, 'learning_rate': 4.5e-05, 'epoch': 0.91}\n{'loss': 1.5572, 'grad_norm': 2.4038355350494385, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.82}\n{'loss': 1.3988, 'grad_norm': 1.5711910724639893, 'learning_rate': 4.4700268840168045e-05, 'epoch': 2.73}\n{'loss': 1.1327, 'grad_norm': 1.4163823127746582, 'learning_rate': 3.824798160583012e-05, 'epoch': 3.64}\n{'loss': 1.0462, 'grad_norm': 1.154224157333374, 'learning_rate': 3.0197792270443982e-05, 'epoch': 4.55}\n{'loss': 0.8919, 'grad_norm': 1.307676076889038, 'learning_rate': 2.1520672475998373e-05, 'epoch': 5.45}\n{'loss': 0.8028, 'grad_norm': 1.585915446281433, 'learning_rate': 1.3263210930352737e-05, 'epoch': 6.36}\n{'loss': 0.793, 'grad_norm': 1.3649868965148926, 'learning_rate': 6.421379363065142e-06, 'epoch': 7.27}\n{'loss': 0.7475, 'grad_norm': 1.198738694190979, 'learning_rate': 1.8204036358303173e-06, 'epoch': 8.18}\n{'loss': 0.6902, 'grad_norm': 1.1372677087783813, 'learning_rate': 1.522932452260595e-08, 'epoch': 9.09}\n100%|█████████████████████████████████████████| 100/100 [01:00<00:00,  1.77it/s][INFO|trainer.py:3984] 2025-05-11 13:55:22,776 >> Saving model checkpoint to trainer_output/checkpoint-100\n[INFO|configuration_utils.py:419] 2025-05-11 13:55:22,778 >> Configuration saved in trainer_output/checkpoint-100/config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 13:55:24,653 >> Model weights saved in trainer_output/checkpoint-100/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 13:55:24,654 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 13:55:24,655 >> tokenizer config file saved in trainer_output/checkpoint-100/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 13:55:24,655 >> Special tokens file saved in trainer_output/checkpoint-100/special_tokens_map.json\n[INFO|trainer.py:2681] 2025-05-11 13:55:27,261 >> \n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n{'train_runtime': 64.8103, 'train_samples_per_second': 12.344, 'train_steps_per_second': 1.543, 'train_loss': 1.2365490627288818, 'epoch': 9.09}\n100%|█████████████████████████████████████████| 100/100 [01:04<00:00,  1.54it/s]\n[INFO|trainer.py:3984] 2025-05-11 13:55:27,264 >> Saving model checkpoint to trainer_output\n[INFO|configuration_utils.py:419] 2025-05-11 13:55:27,265 >> Configuration saved in trainer_output/config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 13:55:29,141 >> Model weights saved in trainer_output/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 13:55:29,141 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 13:55:29,148 >> tokenizer config file saved in trainer_output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 13:55:29,149 >> Special tokens file saved in trainer_output/special_tokens_map.json\n***** train metrics *****\n  epoch                    =     9.0909\n  total_flos               =    69715GF\n  train_loss               =     1.2365\n  train_runtime            = 0:01:04.81\n  train_samples_per_second =     12.344\n  train_steps_per_second   =      1.543\n[INFO|trainer.py:4307] 2025-05-11 13:55:29,195 >> \n***** Running Evaluation *****\n[INFO|trainer.py:4309] 2025-05-11 13:55:29,195 >>   Num examples = 15\n[INFO|trainer.py:4312] 2025-05-11 13:55:29,195 >>   Batch size = 4\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 10.05it/s]\n***** eval metrics *****\n  epoch                   =     9.0909\n  eval_loss               =      0.839\n  eval_runtime            = 0:00:00.54\n  eval_samples_per_second =     27.761\n  eval_steps_per_second   =      7.403\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Finetune a text classification model","metadata":{}},{"cell_type":"code","source":"!python run_seqclass_finetuning.py ./finetune_json/seqclass.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T13:56:36.626765Z","iopub.execute_input":"2025-05-11T13:56:36.627040Z","iopub.status.idle":"2025-05-11T13:59:07.439609Z","shell.execute_reply.started":"2025-05-11T13:56:36.627020Z","shell.execute_reply":"2025-05-11T13:59:07.438816Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"2025-05-11 13:56:42.737736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746971802.761049    4978 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746971802.768452    4978 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nREADME.md: 100%|███████████████████████████| 1.27k/1.27k [00:00<00:00, 8.14MB/s]\ndstc11_one_intent.csv: 100%|█████████████████| 831k/831k [00:00<00:00, 7.82MB/s]\nGenerating train split: 100%|█████| 4205/4205 [00:00<00:00, 78819.51 examples/s]\nconfig.json: 100%|█████████████████████████████| 795/795 [00:00<00:00, 5.18MB/s]\n[INFO|configuration_utils.py:693] 2025-05-11 13:56:48,022 >> loading configuration file config.json from cache at ./bge-reranker-v2-m3-cache/models--BAAI--bge-reranker-v2-m3/snapshots/953dc6f6f85a1b2dbfca4c34a2796e7dde08d41e/config.json\n[INFO|configuration_utils.py:765] 2025-05-11 13:56:48,023 >> Model config XLMRobertaConfig {\n  \"architectures\": [\n    \"XLMRobertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 8194,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\ntokenizer_config.json: 100%|███████████████| 1.17k/1.17k [00:00<00:00, 7.99MB/s]\nsentencepiece.bpe.model: 100%|█████████████| 5.07M/5.07M [00:00<00:00, 61.1MB/s]\ntokenizer.json: 100%|███████████████████████| 17.1M/17.1M [00:00<00:00, 220MB/s]\nspecial_tokens_map.json: 100%|█████████████████| 964/964 [00:00<00:00, 8.17MB/s]\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:56:48,831 >> loading file sentencepiece.bpe.model from cache at ./bge-reranker-v2-m3-cache/models--BAAI--bge-reranker-v2-m3/snapshots/953dc6f6f85a1b2dbfca4c34a2796e7dde08d41e/sentencepiece.bpe.model\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:56:48,831 >> loading file tokenizer.json from cache at ./bge-reranker-v2-m3-cache/models--BAAI--bge-reranker-v2-m3/snapshots/953dc6f6f85a1b2dbfca4c34a2796e7dde08d41e/tokenizer.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:56:48,831 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:56:48,831 >> loading file special_tokens_map.json from cache at ./bge-reranker-v2-m3-cache/models--BAAI--bge-reranker-v2-m3/snapshots/953dc6f6f85a1b2dbfca4c34a2796e7dde08d41e/special_tokens_map.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:56:48,831 >> loading file tokenizer_config.json from cache at ./bge-reranker-v2-m3-cache/models--BAAI--bge-reranker-v2-m3/snapshots/953dc6f6f85a1b2dbfca4c34a2796e7dde08d41e/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 13:56:48,831 >> loading file chat_template.jinja from cache at None\nPreprocess train dataset (num_proc=4): 100%|█| 3574/3574 [00:01<00:00, 1846.66 e\nPreprocess train dataset (num_proc=4): 100%|█| 631/631 [00:01<00:00, 354.13 exam\nmodel.safetensors: 100%|████████████████████| 2.27G/2.27G [00:09<00:00, 249MB/s]\n[INFO|modeling_utils.py:1124] 2025-05-11 13:57:05,231 >> loading weights file model.safetensors from cache at ./bge-reranker-v2-m3-cache/models--BAAI--bge-reranker-v2-m3/snapshots/953dc6f6f85a1b2dbfca4c34a2796e7dde08d41e/model.safetensors\n[INFO|modeling_utils.py:4920] 2025-05-11 13:57:05,483 >> Some weights of the model checkpoint at BAAI/bge-reranker-v2-m3 were not used when initializing XLMRobertaModel: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[WARNING|modeling_utils.py:4932] 2025-05-11 13:57:05,483 >> Some weights of XLMRobertaModel were not initialized from the model checkpoint at BAAI/bge-reranker-v2-m3 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n[INFO|configuration_utils.py:419] 2025-05-11 13:57:05,495 >> Configuration saved in trainer_output/config.json\n/kaggle/working/chatbot-finetuning/run_seqclass_finetuning.py:325: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n[INFO|trainer.py:698] 2025-05-11 13:57:06,569 >> max_steps is given, it will override any value given in num_train_epochs\n[INFO|trainer.py:2414] 2025-05-11 13:57:06,988 >> ***** Running training *****\n[INFO|trainer.py:2415] 2025-05-11 13:57:06,988 >>   Num examples = 3,574\n[INFO|trainer.py:2416] 2025-05-11 13:57:06,988 >>   Num Epochs = 1\n[INFO|trainer.py:2417] 2025-05-11 13:57:06,988 >>   Instantaneous batch size per device = 2\n[INFO|trainer.py:2419] 2025-05-11 13:57:06,988 >>   Training with DataParallel so batch size has been adjusted to: 4\n[INFO|trainer.py:2420] 2025-05-11 13:57:06,988 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n[INFO|trainer.py:2421] 2025-05-11 13:57:06,988 >>   Gradient Accumulation steps = 2\n[INFO|trainer.py:2422] 2025-05-11 13:57:06,988 >>   Total optimization steps = 100\n[INFO|trainer.py:2423] 2025-05-11 13:57:06,990 >>   Number of trainable parameters = 568,321,618\n  0%|                                                   | 0/100 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-05-11 13:57:07,004 >> You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 8.848, 'grad_norm': 9.571208953857422, 'learning_rate': 4.5e-05, 'epoch': 0.02}\n{'loss': 8.7476, 'grad_norm': 12.998064041137695, 'learning_rate': 4.877641290737884e-05, 'epoch': 0.04}\n{'loss': 8.4804, 'grad_norm': 16.68178939819336, 'learning_rate': 4.4700268840168045e-05, 'epoch': 0.07}\n{'loss': 8.2928, 'grad_norm': 21.327646255493164, 'learning_rate': 3.824798160583012e-05, 'epoch': 0.09}\n{'loss': 8.2157, 'grad_norm': 18.055213928222656, 'learning_rate': 3.0197792270443982e-05, 'epoch': 0.11}\n{'loss': 8.3862, 'grad_norm': 17.9116268157959, 'learning_rate': 2.1520672475998373e-05, 'epoch': 0.13}\n{'loss': 8.3338, 'grad_norm': 18.84130096435547, 'learning_rate': 1.3263210930352737e-05, 'epoch': 0.16}\n{'loss': 8.391, 'grad_norm': 19.350561141967773, 'learning_rate': 6.421379363065142e-06, 'epoch': 0.18}\n{'loss': 7.9349, 'grad_norm': 17.98919677734375, 'learning_rate': 1.8204036358303173e-06, 'epoch': 0.2}\n{'loss': 8.571, 'grad_norm': 20.075557708740234, 'learning_rate': 1.522932452260595e-08, 'epoch': 0.22}\n100%|█████████████████████████████████████████| 100/100 [00:50<00:00,  2.09it/s][INFO|trainer.py:3984] 2025-05-11 13:57:57,178 >> Saving model checkpoint to trainer_output/checkpoint-100\n[INFO|trainer.py:3998] 2025-05-11 13:57:57,181 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 13:58:02,924 >> tokenizer config file saved in trainer_output/checkpoint-100/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 13:58:02,925 >> Special tokens file saved in trainer_output/checkpoint-100/special_tokens_map.json\n[INFO|trainer.py:2681] 2025-05-11 13:58:12,221 >> \n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n{'train_runtime': 65.2316, 'train_samples_per_second': 12.264, 'train_steps_per_second': 1.533, 'train_loss': 8.420121688842773, 'epoch': 0.22}\n100%|█████████████████████████████████████████| 100/100 [01:05<00:00,  1.53it/s]\n[INFO|trainer.py:3984] 2025-05-11 13:58:12,225 >> Saving model checkpoint to trainer_output\n[INFO|trainer.py:3998] 2025-05-11 13:58:12,228 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 13:58:21,914 >> tokenizer config file saved in trainer_output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 13:58:21,915 >> Special tokens file saved in trainer_output/special_tokens_map.json\n***** train metrics *****\n  epoch                    =     0.2237\n  total_flos               =        0GF\n  train_loss               =     8.4201\n  train_runtime            = 0:01:05.23\n  train_samples_per_second =     12.264\n  train_steps_per_second   =      1.533\n[INFO|trainer.py:4307] 2025-05-11 13:58:22,042 >> \n***** Running Evaluation *****\n[INFO|trainer.py:4309] 2025-05-11 13:58:22,042 >>   Num examples = 631\n[INFO|trainer.py:4312] 2025-05-11 13:58:22,042 >>   Batch size = 4\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n100%|█████████████████████████████████████████| 158/158 [00:41<00:00,  3.79it/s]\n***** eval metrics *****\n  epoch                   =     0.2237\n  eval_loss               =     4.0782\n  eval_runtime            = 0:00:42.39\n  eval_samples_per_second =     14.884\n  eval_steps_per_second   =      3.727\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Finetune a chat model","metadata":{}},{"cell_type":"code","source":"!python run_chatbot_finetuning.py ./finetune_json/chatbot.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T22:39:12.145196Z","iopub.execute_input":"2025-05-11T22:39:12.145474Z","iopub.status.idle":"2025-05-11T22:40:28.079423Z","shell.execute_reply.started":"2025-05-11T22:39:12.145451Z","shell.execute_reply":"2025-05-11T22:40:28.078098Z"}},"outputs":[{"name":"stdout","text":"2025-05-11 22:39:18.628715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747003158.654542     365 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747003158.663709     365 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nGenerating train split: 100%|█| 2119719/2119719 [00:07<00:00, 269455.16 examples\nGenerating validation split: 100%|█| 21990/21990 [00:00<00:00, 293495.57 example\nconfig.json: 100%|█████████████████████████| 1.21k/1.21k [00:00<00:00, 5.83MB/s]\n[INFO|configuration_utils.py:693] 2025-05-11 22:39:32,410 >> loading configuration file config.json from cache at ./test_output/cache/models--google-t5--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/config.json\n[INFO|configuration_utils.py:765] 2025-05-11 22:39:32,412 >> Model config T5Config {\n  \"architectures\": [\n    \"T5ForConditionalGeneration\"\n  ],\n  \"classifier_dropout\": 0.0,\n  \"d_ff\": 2048,\n  \"d_kv\": 64,\n  \"d_model\": 512,\n  \"decoder_start_token_id\": 0,\n  \"dense_act_fn\": \"relu\",\n  \"dropout_rate\": 0.1,\n  \"eos_token_id\": 1,\n  \"feed_forward_proj\": \"relu\",\n  \"initializer_factor\": 1.0,\n  \"is_encoder_decoder\": true,\n  \"is_gated_act\": false,\n  \"layer_norm_epsilon\": 1e-06,\n  \"model_type\": \"t5\",\n  \"n_positions\": 512,\n  \"num_decoder_layers\": 6,\n  \"num_heads\": 8,\n  \"num_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"relative_attention_max_distance\": 128,\n  \"relative_attention_num_buckets\": 32,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 200,\n      \"min_length\": 30,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4,\n      \"prefix\": \"summarize: \"\n    },\n    \"translation_en_to_de\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to German: \"\n    },\n    \"translation_en_to_fr\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to French: \"\n    },\n    \"translation_en_to_ro\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to Romanian: \"\n    }\n  },\n  \"transformers_version\": \"4.51.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 32128\n}\n\ntokenizer_config.json: 100%|███████████████| 2.32k/2.32k [00:00<00:00, 14.0MB/s]\nspiece.model: 100%|██████████████████████████| 792k/792k [00:00<00:00, 11.0MB/s]\ntokenizer.json: 100%|██████████████████████| 1.39M/1.39M [00:00<00:00, 10.0MB/s]\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 22:39:33,186 >> loading file spiece.model from cache at ./test_output/cache/models--google-t5--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/spiece.model\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 22:39:33,186 >> loading file tokenizer.json from cache at ./test_output/cache/models--google-t5--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/tokenizer.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 22:39:33,186 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 22:39:33,186 >> loading file special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 22:39:33,186 >> loading file tokenizer_config.json from cache at ./test_output/cache/models--google-t5--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 22:39:33,186 >> loading file chat_template.jinja from cache at None\nPreprocess train dataset (num_proc=4): 100%|█| 100/100 [00:00<00:00, 142.26 exam\nPreprocess train dataset (num_proc=4): 100%|█| 100/100 [00:00<00:00, 198.26 exam\nXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\nmodel.safetensors: 100%|██████████████████████| 242M/242M [00:01<00:00, 214MB/s]\n[INFO|modeling_utils.py:1124] 2025-05-11 22:39:36,597 >> loading weights file model.safetensors from cache at ./test_output/cache/models--google-t5--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/model.safetensors\n[INFO|configuration_utils.py:1142] 2025-05-11 22:39:36,600 >> Generate config GenerationConfig {\n  \"decoder_start_token_id\": 0,\n  \"eos_token_id\": 1,\n  \"pad_token_id\": 0\n}\n\n[INFO|modeling_utils.py:4930] 2025-05-11 22:39:36,674 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n\n[INFO|modeling_utils.py:4938] 2025-05-11 22:39:36,674 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at google-t5/t5-small.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\ngeneration_config.json: 100%|███████████████████| 147/147 [00:00<00:00, 980kB/s]\n[INFO|configuration_utils.py:1097] 2025-05-11 22:39:36,798 >> loading configuration file generation_config.json from cache at ./test_output/cache/models--google-t5--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/generation_config.json\n[INFO|configuration_utils.py:1142] 2025-05-11 22:39:36,798 >> Generate config GenerationConfig {\n  \"decoder_start_token_id\": 0,\n  \"eos_token_id\": 1,\n  \"pad_token_id\": 0\n}\n\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:39:36,801 >> tokenizer config file saved in ./test_output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:39:36,801 >> Special tokens file saved in ./test_output/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:39:36,802 >> Copy vocab file to ./test_output/spiece.model\n[INFO|configuration_utils.py:419] 2025-05-11 22:39:36,811 >> Configuration saved in ./test_output/config.json\n[INFO|trainer.py:698] 2025-05-11 22:39:37,192 >> max_steps is given, it will override any value given in num_train_epochs\n[INFO|trainer.py:748] 2025-05-11 22:39:37,193 >> Using auto half precision backend\n[INFO|trainer.py:930] 2025-05-11 22:39:37,585 >> The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: tokens_input_length. If tokens_input_length are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n[INFO|trainer.py:2414] 2025-05-11 22:39:37,598 >> ***** Running training *****\n[INFO|trainer.py:2415] 2025-05-11 22:39:37,598 >>   Num examples = 100\n[INFO|trainer.py:2416] 2025-05-11 22:39:37,598 >>   Num Epochs = 9\n[INFO|trainer.py:2417] 2025-05-11 22:39:37,598 >>   Instantaneous batch size per device = 2\n[INFO|trainer.py:2419] 2025-05-11 22:39:37,598 >>   Training with DataParallel so batch size has been adjusted to: 4\n[INFO|trainer.py:2420] 2025-05-11 22:39:37,598 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n[INFO|trainer.py:2421] 2025-05-11 22:39:37,598 >>   Gradient Accumulation steps = 2\n[INFO|trainer.py:2422] 2025-05-11 22:39:37,599 >>   Total optimization steps = 100\n[INFO|trainer.py:2423] 2025-05-11 22:39:37,599 >>   Number of trainable parameters = 60,506,624\n  0%|                                                   | 0/100 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-05-11 22:39:37,616 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n[WARNING|logging.py:328] 2025-05-11 22:39:38,798 >> Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 2.247, 'grad_norm': 721338.5625, 'learning_rate': 4.8e-05, 'epoch': 0.4}\n{'loss': 1.4383, 'grad_norm': 714451.0, 'learning_rate': 4.55e-05, 'epoch': 0.8}\n 10%|████▏                                     | 10/100 [00:04<00:26,  3.39it/s][INFO|trainer.py:3984] 2025-05-11 22:39:41,968 >> Saving model checkpoint to ./test_output/checkpoint-10\n[INFO|configuration_utils.py:419] 2025-05-11 22:39:41,969 >> Configuration saved in ./test_output/checkpoint-10/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:39:41,970 >> Configuration saved in ./test_output/checkpoint-10/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:39:42,585 >> Model weights saved in ./test_output/checkpoint-10/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:39:42,585 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:39:42,587 >> tokenizer config file saved in ./test_output/checkpoint-10/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:39:42,588 >> Special tokens file saved in ./test_output/checkpoint-10/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:39:42,589 >> Copy vocab file to ./test_output/checkpoint-10/spiece.model\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.757, 'grad_norm': 233219.390625, 'learning_rate': 4.3e-05, 'epoch': 1.16}\n{'loss': 0.7611, 'grad_norm': 178599.703125, 'learning_rate': 4.05e-05, 'epoch': 1.56}\n 20%|████████▍                                 | 20/100 [00:08<00:23,  3.39it/s][INFO|trainer.py:3984] 2025-05-11 22:39:46,103 >> Saving model checkpoint to ./test_output/checkpoint-20\n[INFO|configuration_utils.py:419] 2025-05-11 22:39:46,105 >> Configuration saved in ./test_output/checkpoint-20/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:39:46,105 >> Configuration saved in ./test_output/checkpoint-20/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:39:46,727 >> Model weights saved in ./test_output/checkpoint-20/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:39:46,727 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:39:46,729 >> tokenizer config file saved in ./test_output/checkpoint-20/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:39:46,729 >> Special tokens file saved in ./test_output/checkpoint-20/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:39:46,730 >> Copy vocab file to ./test_output/checkpoint-20/spiece.model\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.4715, 'grad_norm': 156718.953125, 'learning_rate': 3.8e-05, 'epoch': 1.96}\n{'loss': 0.4324, 'grad_norm': 167977.921875, 'learning_rate': 3.55e-05, 'epoch': 2.32}\n 30%|████████████▌                             | 30/100 [00:12<00:20,  3.41it/s][INFO|trainer.py:3984] 2025-05-11 22:39:50,230 >> Saving model checkpoint to ./test_output/checkpoint-30\n[INFO|configuration_utils.py:419] 2025-05-11 22:39:50,232 >> Configuration saved in ./test_output/checkpoint-30/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:39:50,232 >> Configuration saved in ./test_output/checkpoint-30/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:39:50,864 >> Model weights saved in ./test_output/checkpoint-30/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:39:50,865 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:39:50,867 >> tokenizer config file saved in ./test_output/checkpoint-30/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:39:50,867 >> Special tokens file saved in ./test_output/checkpoint-30/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:39:50,868 >> Copy vocab file to ./test_output/checkpoint-30/spiece.model\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.3473, 'grad_norm': 163216.546875, 'learning_rate': 3.3e-05, 'epoch': 2.72}\n{'loss': 0.2869, 'grad_norm': 248907.96875, 'learning_rate': 3.05e-05, 'epoch': 3.08}\n 40%|████████████████▊                         | 40/100 [00:16<00:16,  3.63it/s][INFO|trainer.py:3984] 2025-05-11 22:39:54,505 >> Saving model checkpoint to ./test_output/checkpoint-40\n[INFO|configuration_utils.py:419] 2025-05-11 22:39:54,506 >> Configuration saved in ./test_output/checkpoint-40/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:39:54,507 >> Configuration saved in ./test_output/checkpoint-40/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:39:55,134 >> Model weights saved in ./test_output/checkpoint-40/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:39:55,134 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:39:55,136 >> tokenizer config file saved in ./test_output/checkpoint-40/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:39:55,137 >> Special tokens file saved in ./test_output/checkpoint-40/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:39:55,138 >> Copy vocab file to ./test_output/checkpoint-40/spiece.model\n[INFO|trainer.py:4083] 2025-05-11 22:39:55,966 >> Deleting older checkpoint [test_output/checkpoint-10] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.2573, 'grad_norm': 128914.6875, 'learning_rate': 2.8000000000000003e-05, 'epoch': 3.48}\n{'loss': 0.255, 'grad_norm': 90726.71875, 'learning_rate': 2.5500000000000003e-05, 'epoch': 3.88}\n 50%|█████████████████████                     | 50/100 [00:21<00:17,  2.93it/s][INFO|trainer.py:3984] 2025-05-11 22:39:59,524 >> Saving model checkpoint to ./test_output/checkpoint-50\n[INFO|configuration_utils.py:419] 2025-05-11 22:39:59,526 >> Configuration saved in ./test_output/checkpoint-50/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:39:59,526 >> Configuration saved in ./test_output/checkpoint-50/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:40:00,162 >> Model weights saved in ./test_output/checkpoint-50/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:40:00,162 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:40:00,164 >> tokenizer config file saved in ./test_output/checkpoint-50/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:40:00,165 >> Special tokens file saved in ./test_output/checkpoint-50/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:40:00,166 >> Copy vocab file to ./test_output/checkpoint-50/spiece.model\n[INFO|trainer.py:4083] 2025-05-11 22:40:01,014 >> Deleting older checkpoint [test_output/checkpoint-20] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.248, 'grad_norm': 72287.0234375, 'learning_rate': 2.3000000000000003e-05, 'epoch': 4.24}\n{'loss': 0.2332, 'grad_norm': 94447.9140625, 'learning_rate': 2.05e-05, 'epoch': 4.64}\n 60%|█████████████████████████▏                | 60/100 [00:26<00:13,  2.91it/s][INFO|trainer.py:3984] 2025-05-11 22:40:04,018 >> Saving model checkpoint to ./test_output/checkpoint-60\n[INFO|configuration_utils.py:419] 2025-05-11 22:40:04,020 >> Configuration saved in ./test_output/checkpoint-60/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:40:04,020 >> Configuration saved in ./test_output/checkpoint-60/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:40:04,626 >> Model weights saved in ./test_output/checkpoint-60/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:40:04,626 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:40:04,628 >> tokenizer config file saved in ./test_output/checkpoint-60/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:40:04,628 >> Special tokens file saved in ./test_output/checkpoint-60/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:40:04,629 >> Copy vocab file to ./test_output/checkpoint-60/spiece.model\n[INFO|trainer.py:4083] 2025-05-11 22:40:05,421 >> Deleting older checkpoint [test_output/checkpoint-30] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.2397, 'grad_norm': 43940.375, 'learning_rate': 1.8e-05, 'epoch': 5.0}\n{'loss': 0.1626, 'grad_norm': 72285.3359375, 'learning_rate': 1.55e-05, 'epoch': 5.4}\n 70%|█████████████████████████████▍            | 70/100 [00:30<00:08,  3.35it/s][INFO|trainer.py:3984] 2025-05-11 22:40:08,303 >> Saving model checkpoint to ./test_output/checkpoint-70\n[INFO|configuration_utils.py:419] 2025-05-11 22:40:08,305 >> Configuration saved in ./test_output/checkpoint-70/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:40:08,305 >> Configuration saved in ./test_output/checkpoint-70/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:40:08,948 >> Model weights saved in ./test_output/checkpoint-70/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:40:08,948 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:40:08,950 >> tokenizer config file saved in ./test_output/checkpoint-70/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:40:08,950 >> Special tokens file saved in ./test_output/checkpoint-70/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:40:08,951 >> Copy vocab file to ./test_output/checkpoint-70/spiece.model\n[INFO|trainer.py:4083] 2025-05-11 22:40:09,846 >> Deleting older checkpoint [test_output/checkpoint-40] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.2212, 'grad_norm': 78063.4296875, 'learning_rate': 1.3000000000000001e-05, 'epoch': 5.8}\n{'loss': 0.1561, 'grad_norm': 68388.796875, 'learning_rate': 1.05e-05, 'epoch': 6.16}\n 80%|█████████████████████████████████▌        | 80/100 [00:35<00:06,  3.32it/s][INFO|trainer.py:3984] 2025-05-11 22:40:12,967 >> Saving model checkpoint to ./test_output/checkpoint-80\n[INFO|configuration_utils.py:419] 2025-05-11 22:40:12,969 >> Configuration saved in ./test_output/checkpoint-80/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:40:12,970 >> Configuration saved in ./test_output/checkpoint-80/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:40:13,594 >> Model weights saved in ./test_output/checkpoint-80/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:40:13,594 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:40:13,596 >> tokenizer config file saved in ./test_output/checkpoint-80/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:40:13,597 >> Special tokens file saved in ./test_output/checkpoint-80/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:40:13,598 >> Copy vocab file to ./test_output/checkpoint-80/spiece.model\n[INFO|trainer.py:4083] 2025-05-11 22:40:14,403 >> Deleting older checkpoint [test_output/checkpoint-50] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.155, 'grad_norm': 55544.87890625, 'learning_rate': 8.000000000000001e-06, 'epoch': 6.56}\n{'loss': 0.2303, 'grad_norm': 74385.21875, 'learning_rate': 5.500000000000001e-06, 'epoch': 6.96}\n 90%|█████████████████████████████████████▊    | 90/100 [00:39<00:03,  3.10it/s][INFO|trainer.py:3984] 2025-05-11 22:40:17,599 >> Saving model checkpoint to ./test_output/checkpoint-90\n[INFO|configuration_utils.py:419] 2025-05-11 22:40:17,601 >> Configuration saved in ./test_output/checkpoint-90/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:40:17,601 >> Configuration saved in ./test_output/checkpoint-90/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:40:18,213 >> Model weights saved in ./test_output/checkpoint-90/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:40:18,214 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:40:18,215 >> tokenizer config file saved in ./test_output/checkpoint-90/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:40:18,216 >> Special tokens file saved in ./test_output/checkpoint-90/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:40:18,217 >> Copy vocab file to ./test_output/checkpoint-90/spiece.model\n[INFO|trainer.py:4083] 2025-05-11 22:40:19,085 >> Deleting older checkpoint [test_output/checkpoint-60] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.1548, 'grad_norm': 77625.640625, 'learning_rate': 3e-06, 'epoch': 7.32}\n{'loss': 0.1507, 'grad_norm': 75939.40625, 'learning_rate': 5.000000000000001e-07, 'epoch': 7.72}\n100%|█████████████████████████████████████████| 100/100 [00:44<00:00,  3.35it/s][INFO|trainer.py:3984] 2025-05-11 22:40:21,920 >> Saving model checkpoint to ./test_output/checkpoint-100\n[INFO|configuration_utils.py:419] 2025-05-11 22:40:21,922 >> Configuration saved in ./test_output/checkpoint-100/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:40:21,922 >> Configuration saved in ./test_output/checkpoint-100/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:40:22,560 >> Model weights saved in ./test_output/checkpoint-100/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:40:22,561 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:40:22,563 >> tokenizer config file saved in ./test_output/checkpoint-100/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:40:22,563 >> Special tokens file saved in ./test_output/checkpoint-100/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:40:22,564 >> Copy vocab file to ./test_output/checkpoint-100/spiece.model\n[INFO|trainer.py:4083] 2025-05-11 22:40:23,379 >> Deleting older checkpoint [test_output/checkpoint-70] due to args.save_total_limit\n[INFO|trainer.py:2681] 2025-05-11 22:40:23,539 >> \n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n{'train_runtime': 45.9401, 'train_samples_per_second': 17.414, 'train_steps_per_second': 2.177, 'train_loss': 0.4602722489833832, 'epoch': 7.72}\n100%|█████████████████████████████████████████| 100/100 [00:45<00:00,  2.18it/s]\n[INFO|trainer.py:3984] 2025-05-11 22:40:23,542 >> Saving model checkpoint to ./test_output\n[INFO|configuration_utils.py:419] 2025-05-11 22:40:23,543 >> Configuration saved in ./test_output/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 22:40:23,544 >> Configuration saved in ./test_output/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 22:40:24,144 >> Model weights saved in ./test_output/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 22:40:24,144 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 22:40:24,146 >> tokenizer config file saved in ./test_output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 22:40:24,147 >> Special tokens file saved in ./test_output/special_tokens_map.json\n[INFO|tokenization_t5_fast.py:176] 2025-05-11 22:40:24,148 >> Copy vocab file to ./test_output/spiece.model\n***** train metrics *****\n  epoch                    =       7.72\n  total_flos               =    24327GF\n  train_loss               =     0.4603\n  train_runtime            = 0:00:45.94\n  train_samples_per_second =     17.414\n  train_steps_per_second   =      2.177\n[INFO|trainer.py:930] 2025-05-11 22:40:24,159 >> The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: tokens_input_length. If tokens_input_length are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n[INFO|trainer.py:4307] 2025-05-11 22:40:24,163 >> \n***** Running Evaluation *****\n[INFO|trainer.py:4309] 2025-05-11 22:40:24,163 >>   Num examples = 100\n[INFO|trainer.py:4312] 2025-05-11 22:40:24,163 >>   Batch size = 4\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n100%|███████████████████████████████████████████| 25/25 [00:01<00:00, 18.63it/s]\n***** eval metrics *****\n  epoch                   =       7.72\n  eval_loss               =     0.2404\n  eval_runtime            = 0:00:01.39\n  eval_samples_per_second =     71.788\n  eval_steps_per_second   =     17.947\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Finetune an imagecap model","metadata":{}},{"cell_type":"code","source":"!python run_imagecap_finetuning.py ./finetune_json/imagecap.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T14:28:19.596878Z","iopub.execute_input":"2025-05-11T14:28:19.597281Z","iopub.status.idle":"2025-05-11T14:32:13.101044Z","shell.execute_reply.started":"2025-05-11T14:28:19.597257Z","shell.execute_reply":"2025-05-11T14:32:13.100110Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"2025-05-11 14:28:25.180826: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746973705.205482    5869 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746973705.212650    5869 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nGenerating train split: 100%|████| 13896/13896 [00:07<00:00, 1868.69 examples/s]\nconfig.json: 100%|█████████████████████████| 4.56k/4.56k [00:00<00:00, 20.4MB/s]\n[INFO|configuration_utils.py:693] 2025-05-11 14:28:37,865 >> loading configuration file config.json from cache at ./blip-image-captioning-base-cache/models--Salesforce--blip-image-captioning-base/snapshots/82a37760796d32b1411fe092ab5d4e227313294b/config.json\n[INFO|configuration_blip.py:298] 2025-05-11 14:28:37,867 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:28:37,867 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_utils.py:765] 2025-05-11 14:28:37,868 >> Model config BlipConfig {\n  \"architectures\": [\n    \"BlipForConditionalGeneration\"\n  ],\n  \"image_text_hidden_size\": 256,\n  \"initializer_factor\": 1.0,\n  \"initializer_range\": 0.02,\n  \"label_smoothing\": 0.0,\n  \"logit_scale_init_value\": 2.6592,\n  \"model_type\": \"blip\",\n  \"projection_dim\": 512,\n  \"text_config\": {\n    \"attention_probs_dropout_prob\": 0.0,\n    \"encoder_hidden_size\": 768,\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.0,\n    \"hidden_size\": 768,\n    \"initializer_factor\": 1.0,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"label_smoothing\": 0.0,\n    \"layer_norm_eps\": 1e-12,\n    \"max_position_embeddings\": 512,\n    \"model_type\": \"blip_text_model\",\n    \"num_attention_heads\": 12,\n    \"num_hidden_layers\": 12,\n    \"projection_dim\": 768,\n    \"use_cache\": true,\n    \"vocab_size\": 30524\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.1\",\n  \"vision_config\": {\n    \"attention_dropout\": 0.0,\n    \"dropout\": 0.0,\n    \"hidden_act\": \"gelu\",\n    \"hidden_size\": 768,\n    \"image_size\": 384,\n    \"initializer_factor\": 1.0,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"layer_norm_eps\": 1e-05,\n    \"model_type\": \"blip_vision_model\",\n    \"num_attention_heads\": 12,\n    \"num_channels\": 3,\n    \"num_hidden_layers\": 12,\n    \"patch_size\": 16,\n    \"projection_dim\": 512\n  }\n}\n\npreprocessor_config.json: 100%|████████████████| 287/287 [00:00<00:00, 2.36MB/s]\n[INFO|image_processing_base.py:380] 2025-05-11 14:28:37,990 >> loading configuration file preprocessor_config.json from cache at ./blip-image-captioning-base-cache/models--Salesforce--blip-image-captioning-base/snapshots/82a37760796d32b1411fe092ab5d4e227313294b/preprocessor_config.json\n[WARNING|logging.py:328] 2025-05-11 14:28:37,990 >> Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n[INFO|image_processing_utils.py:239] 2025-05-11 14:28:37,991 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}, {'max_width', 'max_height'}), got 384. Converted to {'height': 384, 'width': 384}.\n[INFO|image_processing_base.py:433] 2025-05-11 14:28:37,991 >> Image processor BlipImageProcessor {\n  \"do_convert_rgb\": true,\n  \"do_normalize\": true,\n  \"do_rescale\": true,\n  \"do_resize\": true,\n  \"image_mean\": [\n    0.48145466,\n    0.4578275,\n    0.40821073\n  ],\n  \"image_processor_type\": \"BlipImageProcessor\",\n  \"image_std\": [\n    0.26862954,\n    0.26130258,\n    0.27577711\n  ],\n  \"processor_class\": \"BlipProcessor\",\n  \"resample\": 3,\n  \"rescale_factor\": 0.00392156862745098,\n  \"size\": {\n    \"height\": 384,\n    \"width\": 384\n  }\n}\n\ntokenizer_config.json: 100%|███████████████████| 506/506 [00:00<00:00, 2.80MB/s]\nvocab.txt: 100%|█████████████████████████████| 232k/232k [00:00<00:00, 5.24MB/s]\ntokenizer.json: 100%|████████████████████████| 711k/711k [00:00<00:00, 18.8MB/s]\nspecial_tokens_map.json: 100%|██████████████████| 125/125 [00:00<00:00, 953kB/s]\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 14:28:38,699 >> loading file vocab.txt from cache at ./blip-image-captioning-base-cache/models--Salesforce--blip-image-captioning-base/snapshots/82a37760796d32b1411fe092ab5d4e227313294b/vocab.txt\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 14:28:38,699 >> loading file tokenizer.json from cache at ./blip-image-captioning-base-cache/models--Salesforce--blip-image-captioning-base/snapshots/82a37760796d32b1411fe092ab5d4e227313294b/tokenizer.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 14:28:38,699 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 14:28:38,700 >> loading file special_tokens_map.json from cache at ./blip-image-captioning-base-cache/models--Salesforce--blip-image-captioning-base/snapshots/82a37760796d32b1411fe092ab5d4e227313294b/special_tokens_map.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 14:28:38,700 >> loading file tokenizer_config.json from cache at ./blip-image-captioning-base-cache/models--Salesforce--blip-image-captioning-base/snapshots/82a37760796d32b1411fe092ab5d4e227313294b/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2060] 2025-05-11 14:28:38,700 >> loading file chat_template.jinja from cache at None\nProcessing images: 100%|███████████████| 100/100 [00:06<00:00, 14.38 examples/s]\nFilter: 100%|██████████████████████████| 100/100 [00:19<00:00,  5.02 examples/s]\nProcessing images: 100%|███████████████| 100/100 [00:06<00:00, 16.50 examples/s]\nFilter: 100%|██████████████████████████| 100/100 [00:19<00:00,  5.10 examples/s]\n[INFO|configuration_utils.py:693] 2025-05-11 14:29:31,359 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--blip-image-captioning-base/snapshots/82a37760796d32b1411fe092ab5d4e227313294b/config.json\n[INFO|configuration_blip.py:298] 2025-05-11 14:29:31,360 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:29:31,360 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_utils.py:765] 2025-05-11 14:29:31,361 >> Model config BlipConfig {\n  \"architectures\": [\n    \"BlipForConditionalGeneration\"\n  ],\n  \"image_text_hidden_size\": 256,\n  \"initializer_factor\": 1.0,\n  \"initializer_range\": 0.02,\n  \"label_smoothing\": 0.0,\n  \"logit_scale_init_value\": 2.6592,\n  \"model_type\": \"blip\",\n  \"projection_dim\": 512,\n  \"text_config\": {\n    \"attention_probs_dropout_prob\": 0.0,\n    \"encoder_hidden_size\": 768,\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.0,\n    \"hidden_size\": 768,\n    \"initializer_factor\": 1.0,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"label_smoothing\": 0.0,\n    \"layer_norm_eps\": 1e-12,\n    \"max_position_embeddings\": 512,\n    \"model_type\": \"blip_text_model\",\n    \"num_attention_heads\": 12,\n    \"num_hidden_layers\": 12,\n    \"projection_dim\": 768,\n    \"use_cache\": true,\n    \"vocab_size\": 30524\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.1\",\n  \"vision_config\": {\n    \"attention_dropout\": 0.0,\n    \"dropout\": 0.0,\n    \"hidden_act\": \"gelu\",\n    \"hidden_size\": 768,\n    \"image_size\": 384,\n    \"initializer_factor\": 1.0,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"layer_norm_eps\": 1e-05,\n    \"model_type\": \"blip_vision_model\",\n    \"num_attention_heads\": 12,\n    \"num_channels\": 3,\n    \"num_hidden_layers\": 12,\n    \"patch_size\": 16,\n    \"projection_dim\": 512\n  }\n}\n\n[INFO|modeling_utils.py:1124] 2025-05-11 14:29:31,558 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--Salesforce--blip-image-captioning-base/snapshots/82a37760796d32b1411fe092ab5d4e227313294b/pytorch_model.bin\n[INFO|configuration_utils.py:1142] 2025-05-11 14:29:31,560 >> Generate config GenerationConfig {}\n\n[INFO|configuration_utils.py:1142] 2025-05-11 14:29:31,574 >> Generate config GenerationConfig {\n  \"bos_token_id\": 30522,\n  \"eos_token_id\": 2,\n  \"pad_token_id\": 0\n}\n\n[INFO|safetensors_conversion.py:61] 2025-05-11 14:29:31,752 >> Attempting to create safetensors variant\n[INFO|modeling_utils.py:4930] 2025-05-11 14:29:31,926 >> All model checkpoint weights were used when initializing BlipForConditionalGeneration.\n\n[INFO|modeling_utils.py:4938] 2025-05-11 14:29:31,926 >> All the weights of BlipForConditionalGeneration were initialized from the model checkpoint at Salesforce/blip-image-captioning-base.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BlipForConditionalGeneration for predictions without further training.\n[INFO|modeling_utils.py:4443] 2025-05-11 14:29:31,987 >> Generation config file not found, using a generation config created from the model config.\n[INFO|image_processing_base.py:260] 2025-05-11 14:29:31,987 >> Image processor saved in trainer_output/preprocessor_config.json\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 14:29:31,988 >> tokenizer config file saved in trainer_output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 14:29:31,988 >> Special tokens file saved in trainer_output/special_tokens_map.json\n[INFO|configuration_blip.py:298] 2025-05-11 14:29:32,001 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|safetensors_conversion.py:74] 2025-05-11 14:29:32,002 >> Safetensors PR exists\n[INFO|configuration_blip.py:302] 2025-05-11 14:29:32,002 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_blip.py:298] 2025-05-11 14:29:32,005 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:29:32,005 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_utils.py:419] 2025-05-11 14:29:32,006 >> Configuration saved in trainer_output/config.json\n[INFO|trainer.py:2414] 2025-05-11 14:29:32,954 >> ***** Running training *****\n[INFO|trainer.py:2415] 2025-05-11 14:29:32,954 >>   Num examples = 100\n[INFO|trainer.py:2416] 2025-05-11 14:29:32,954 >>   Num Epochs = 3\n[INFO|trainer.py:2417] 2025-05-11 14:29:32,954 >>   Instantaneous batch size per device = 8\n[INFO|trainer.py:2419] 2025-05-11 14:29:32,954 >>   Training with DataParallel so batch size has been adjusted to: 16\n[INFO|trainer.py:2420] 2025-05-11 14:29:32,954 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n[INFO|trainer.py:2421] 2025-05-11 14:29:32,954 >>   Gradient Accumulation steps = 1\n[INFO|trainer.py:2422] 2025-05-11 14:29:32,954 >>   Total optimization steps = 21\n[INFO|trainer.py:2423] 2025-05-11 14:29:32,956 >>   Number of trainable parameters = 247,414,076\n[INFO|configuration_blip.py:298] 2025-05-11 14:29:32,962 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:29:32,962 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n  0%|                                                    | 0/21 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-05-11 14:29:37,026 >> You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 2.8562, 'grad_norm': 7.881349563598633, 'learning_rate': 4.058724504646834e-05, 'epoch': 1.0}\n 33%|██████████████▋                             | 7/21 [00:36<00:47,  3.42s/it][INFO|trainer.py:3984] 2025-05-11 14:30:09,611 >> Saving model checkpoint to trainer_output/checkpoint-7\n[INFO|configuration_blip.py:298] 2025-05-11 14:30:09,611 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:30:09,611 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_blip.py:298] 2025-05-11 14:30:09,612 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:30:09,612 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_blip.py:298] 2025-05-11 14:30:09,613 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:30:09,613 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_utils.py:419] 2025-05-11 14:30:09,614 >> Configuration saved in trainer_output/checkpoint-7/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 14:30:09,615 >> Configuration saved in trainer_output/checkpoint-7/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 14:30:11,908 >> Model weights saved in trainer_output/checkpoint-7/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 14:30:11,908 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 14:30:11,909 >> tokenizer config file saved in trainer_output/checkpoint-7/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 14:30:11,909 >> Special tokens file saved in trainer_output/checkpoint-7/special_tokens_map.json\n{'loss': 1.5602, 'grad_norm': 6.5254669189453125, 'learning_rate': 1.5866474390840125e-05, 'epoch': 2.0}\n 67%|████████████████████████████▋              | 14/21 [01:18<00:25,  3.69s/it][INFO|trainer.py:3984] 2025-05-11 14:30:51,297 >> Saving model checkpoint to trainer_output/checkpoint-14\n[INFO|configuration_blip.py:298] 2025-05-11 14:30:51,297 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:30:51,297 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_blip.py:298] 2025-05-11 14:30:51,298 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:30:51,298 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_blip.py:298] 2025-05-11 14:30:51,299 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:30:51,299 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_utils.py:419] 2025-05-11 14:30:51,300 >> Configuration saved in trainer_output/checkpoint-14/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 14:30:51,301 >> Configuration saved in trainer_output/checkpoint-14/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 14:30:53,587 >> Model weights saved in trainer_output/checkpoint-14/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 14:30:53,588 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 14:30:53,589 >> tokenizer config file saved in trainer_output/checkpoint-14/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 14:30:53,589 >> Special tokens file saved in trainer_output/checkpoint-14/special_tokens_map.json\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 1.2986, 'grad_norm': 8.410009384155273, 'learning_rate': 2.7922934437178695e-07, 'epoch': 3.0}\n100%|███████████████████████████████████████████| 21/21 [02:00<00:00,  3.70s/it][INFO|trainer.py:3984] 2025-05-11 14:31:33,238 >> Saving model checkpoint to trainer_output/checkpoint-21\n[INFO|configuration_blip.py:298] 2025-05-11 14:31:33,238 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:31:33,238 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_blip.py:298] 2025-05-11 14:31:33,239 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:31:33,239 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_blip.py:298] 2025-05-11 14:31:33,239 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:31:33,240 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_utils.py:419] 2025-05-11 14:31:33,241 >> Configuration saved in trainer_output/checkpoint-21/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 14:31:33,241 >> Configuration saved in trainer_output/checkpoint-21/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 14:31:35,510 >> Model weights saved in trainer_output/checkpoint-21/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 14:31:35,511 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 14:31:35,512 >> tokenizer config file saved in trainer_output/checkpoint-21/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 14:31:35,512 >> Special tokens file saved in trainer_output/checkpoint-21/special_tokens_map.json\n[INFO|trainer.py:2681] 2025-05-11 14:31:38,389 >> \n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n{'train_runtime': 125.4331, 'train_samples_per_second': 2.392, 'train_steps_per_second': 0.167, 'train_loss': 1.9049787975492931, 'epoch': 3.0}\n100%|███████████████████████████████████████████| 21/21 [02:05<00:00,  5.97s/it]\n[INFO|trainer.py:3984] 2025-05-11 14:31:38,392 >> Saving model checkpoint to trainer_output\n[INFO|configuration_blip.py:298] 2025-05-11 14:31:38,393 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:31:38,393 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_blip.py:298] 2025-05-11 14:31:38,393 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:31:38,393 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_blip.py:298] 2025-05-11 14:31:38,395 >> `text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n[INFO|configuration_blip.py:302] 2025-05-11 14:31:38,395 >> `vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n[INFO|configuration_utils.py:419] 2025-05-11 14:31:38,403 >> Configuration saved in trainer_output/config.json\n[INFO|configuration_utils.py:911] 2025-05-11 14:31:38,404 >> Configuration saved in trainer_output/generation_config.json\n[INFO|modeling_utils.py:3572] 2025-05-11 14:31:40,821 >> Model weights saved in trainer_output/model.safetensors\n[INFO|trainer.py:4017] 2025-05-11 14:31:40,821 >> Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n[INFO|tokenization_utils_base.py:2510] 2025-05-11 14:31:40,863 >> tokenizer config file saved in trainer_output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2519] 2025-05-11 14:31:40,863 >> Special tokens file saved in trainer_output/special_tokens_map.json\n***** train metrics *****\n  epoch                    =         3.0\n  total_flos               = 165800653GF\n  train_loss               =       1.905\n  train_runtime            =  0:02:05.43\n  train_samples_per_second =       2.392\n  train_steps_per_second   =       0.167\n[INFO|trainer.py:4307] 2025-05-11 14:31:40,939 >> \n***** Running Evaluation *****\n[INFO|trainer.py:4309] 2025-05-11 14:31:40,939 >>   Num examples = 100\n[INFO|trainer.py:4312] 2025-05-11 14:31:40,939 >>   Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n100%|█████████████████████████████████████████████| 7/7 [00:21<00:00,  3.06s/it]\n***** eval metrics *****\n  epoch                   =        3.0\n  eval_loss               =     1.4683\n  eval_runtime            = 0:00:29.62\n  eval_samples_per_second =      3.376\n  eval_steps_per_second   =      0.236\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}